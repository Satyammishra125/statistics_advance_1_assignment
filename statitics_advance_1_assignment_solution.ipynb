{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATISTICS ADVANCE 1 ASSIGNMENT SOLUTION\n",
    "## Question 1. Explain the properties of the F-distribution. \n",
    "Ans. The **F-distribution** is a special type of probability distribution used when comparing the variances of two groups or sets of data. Here’s a simpler breakdown:\n",
    "\n",
    "1. **Shape**: The F-distribution is **skewed to the right**. This means it starts at 0 and stretches out to the right, never going below zero.\n",
    "\n",
    "2. **Used for Ratios**: It's used when you're comparing two variances (spread of data). For example, if you're testing whether two groups have the same amount of variation, you'd use an F-distribution.\n",
    "\n",
    "3. **Degrees of Freedom**: It has two key numbers called \"degrees of freedom\" (df):\n",
    "   - One for the **top** (numerator) part of the ratio.\n",
    "   - One for the **bottom** (denominator) part of the ratio.\n",
    "   The shape of the F-distribution depends on these numbers.\n",
    "\n",
    "4. **Range**: The F-distribution only gives values greater than or equal to 0 (it never goes negative).\n",
    "\n",
    "5. **Mean**: The average value of the F-distribution depends on the degrees of freedom. For large numbers, the mean is around 1.\n",
    "\n",
    "6. **Why It's Used**: It helps test whether the differences between two groups are likely due to random chance or if they represent a real difference (for example, in experiments comparing different treatments or models).\n",
    "\n",
    "### Example:\n",
    "If you're comparing the variances of two different diets in an experiment, you'd use the F-distribution to check if one diet is significantly more \"spread out\" (more variable) than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?\n",
    "Ans. The **F-distribution** is used in several types of statistical tests where we compare **variability (spread)** between groups or models. Here are the main tests where it's used:\n",
    "\n",
    "### 1. **ANOVA (Analysis of Variance)**:\n",
    "   - **What it does**: ANOVA helps compare the means (average values) of **three or more groups** to see if they are significantly different from each other.\n",
    "   - **Why F-distribution is used**: It compares how much the group means differ from each other (between-group variance) to how much the data varies within each group (within-group variance). The F-distribution helps determine if the difference in means is big enough to be real, or if it’s just due to random chance.\n",
    "\n",
    "### 2. **Regression Analysis (F-test)**:\n",
    "   - **What it does**: In regression, we try to predict one thing based on other factors (like predicting test scores based on hours studied). The F-test checks if the model we are using to make predictions is doing a good job explaining the data.\n",
    "   - **Why F-distribution is used**: It compares the variance explained by the model (how well the factors predict the outcome) to the unexplained variance (random error). If the model explains a lot, the F-statistic will be large, and the F-distribution helps decide if that’s statistically significant.\n",
    "\n",
    "### 3. **F-test for Two Variances**:\n",
    "   - **What it does**: This test compares the **variances (spread)** of two groups to see if they are equal or different.\n",
    "   - **Why F-distribution is used**: The test looks at the ratio of the two variances. The F-distribution tells us if this ratio is large enough to conclude that the variances are different, or if it’s just due to random variation.\n",
    "\n",
    "---\n",
    "\n",
    "### Why F-distribution is the right choice for these tests:\n",
    "- **It compares variability (variance)**: The F-distribution is based on ratios of variances. Since variances can never be negative, the F-distribution only takes values from 0 and above.\n",
    "- **It helps spot large differences**: The F-distribution is useful when looking for large differences in variability. If one group has much more spread than another, the F-test will detect that.\n",
    "- **It adjusts for sample size**: The F-distribution considers how many data points are in each group, so it gives a more accurate result depending on the sample size.\n",
    "\n",
    "### In short:\n",
    "- **ANOVA**: Used to compare the averages of multiple groups.\n",
    "- **Regression F-test**: Used to check if a model explains the data well.\n",
    "- **F-test for two variances**: Used to compare the variability between two groups.\n",
    "\n",
    "In all these tests, the **F-distribution** helps us figure out if the differences in variability are real or just due to random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3. What are the key assumptions required for conducting an F-test to compare the variances of two populations?\n",
    "Ans. When you conduct an **F-test** to compare the variances of two populations (for example, to see if two groups have similar variability), there are a few important assumptions that need to be met for the test to be valid:\n",
    "\n",
    "### 1. **The Populations are Normally Distributed**\n",
    "   - **What it means**: Both populations you’re comparing should follow a **normal distribution** (the bell-shaped curve). This is important because the F-test relies on the assumption that the data is symmetrically spread out around the mean.\n",
    "   - **Why it matters**: If the data is heavily skewed or has outliers, the F-test results may not be reliable.\n",
    "\n",
    "### 2. **The Two Populations are Independent**\n",
    "   - **What it means**: The two groups (or samples) you’re comparing should not influence each other. For example, if you're comparing two treatments, the outcome of one group should not affect the other.\n",
    "   - **Why it matters**: If the groups are dependent (i.e., one group is related to the other, like measuring the same individuals before and after an intervention), the F-test may not give the correct result.\n",
    "\n",
    "### 3. **The Samples are Random**\n",
    "   - **What it means**: The samples you’re comparing should be randomly selected from the populations. This helps ensure that the groups are representative of the populations.\n",
    "   - **Why it matters**: If the samples are biased (not chosen randomly), the F-test might not give an accurate picture of the variances.\n",
    "\n",
    "### 4. **The Variances are Positive**\n",
    "   - **What it means**: The variances of both populations must be greater than zero. Variance measures how spread out the data is, so it can’t be negative.\n",
    "   - **Why it matters**: The F-test compares the ratio of variances, and negative variances don’t make sense mathematically.\n",
    "\n",
    "### 5. **The Two Samples are Independent Random Samples**\n",
    "   - **What it means**: The data in each sample should come from independent, random selections from their respective populations. The samples should not influence each other.\n",
    "   - **Why it matters**: If one sample depends on the other (like paired data), the F-test will not work properly.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Key Assumptions for an F-test:\n",
    "1. **Normality**: Both populations should be normally distributed.\n",
    "2. **Independence**: The two groups should be independent of each other.\n",
    "3. **Random Sampling**: The samples should be randomly selected.\n",
    "4. **Positive Variances**: Both populations must have positive variances (no negative spread).\n",
    "   \n",
    "If these assumptions hold, the F-test can help you accurately compare the variances of two populations. If they don’t hold, the F-test might not give reliable results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. What is the purpose of ANOVA, and how does it differ from a t-test? \n",
    "### Purpose of **ANOVA**:\n",
    "\n",
    "Ans. **ANOVA** (Analysis of Variance) is a statistical test used to compare the means of **three or more groups** to see if at least one of them is significantly different from the others. Instead of comparing just two groups, ANOVA allows you to test multiple groups at the same time. It helps answer questions like:\n",
    "\n",
    "- Do different treatments have different effects?\n",
    "- Is there a difference in test scores between several teaching methods?\n",
    "\n",
    "### Why ANOVA?\n",
    "- **When you have multiple groups**: If you're comparing three or more groups, using multiple t-tests would be too complicated and increase the chance of making mistakes (false positives). ANOVA is designed to handle this more efficiently.\n",
    "\n",
    "### How ANOVA Works:\n",
    "ANOVA compares:\n",
    "1. The **variance between** the group means (how far the group averages are from the overall average).\n",
    "2. The **variance within** each group (how spread out the individual data points are within each group).\n",
    "\n",
    "If the variance between groups is much larger than the variance within groups, it suggests that there is a real difference between the groups, and ANOVA will give you a result showing whether those differences are statistically significant.\n",
    "\n",
    "### How ANOVA Differs from a **t-test**:\n",
    "\n",
    "1. **Number of Groups Compared**:\n",
    "   - **t-test**: Used to compare the means of **two groups**.\n",
    "   - **ANOVA**: Used to compare the means of **three or more groups** at the same time.\n",
    "\n",
    "2. **Type of Question**:\n",
    "   - **t-test**: Tests if the average of one group is different from the average of another group.\n",
    "   - **ANOVA**: Tests if there is any difference in the means of multiple groups. It doesn't specify which group is different, just whether at least one group is different from the others.\n",
    "\n",
    "3. **Error Rate**:\n",
    "   - **t-test**: When you perform multiple t-tests (e.g., comparing Group 1 to Group 2, then Group 1 to Group 3, etc.), the chance of making a **Type I error** (false positive) increases.\n",
    "   - **ANOVA**: Handles multiple comparisons at once, so it keeps the **error rate** in check.\n",
    "\n",
    "### Example:\n",
    "- **t-test**: If you're testing whether **Treatment A** is better than **Treatment B**, you would use a t-test.\n",
    "- **ANOVA**: If you're testing whether **Treatment A**, **Treatment B**, and **Treatment C** all produce different results, you would use ANOVA.\n",
    "\n",
    "---\n",
    "\n",
    "### In Simple Terms:\n",
    "- **ANOVA** is for comparing the means of **three or more groups**. It tells you if there are any significant differences among them.\n",
    "- **t-test** is for comparing the means of **two groups** only.\n",
    "\n",
    "If you're only comparing two groups, use a t-test. If you're comparing more than two groups, use ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups.\n",
    "### When and Why to Use **One-Way ANOVA** Instead of Multiple **t-tests**:\n",
    "\n",
    "Ans. If you need to compare **more than two groups** to see if their means are significantly different, using **one-way ANOVA** is typically a better choice than doing multiple **t-tests**. Here's why:\n",
    "\n",
    "### 1. **Reducing the Risk of Type I Error (False Positives)**:\n",
    "   - **Multiple t-tests**: If you conduct several t-tests (e.g., comparing Group 1 vs. Group 2, Group 1 vs. Group 3, Group 2 vs. Group 3), each test carries a risk of a **false positive** (Type I error), where you might incorrectly conclude that a difference exists when it doesn't.\n",
    "   - **One-Way ANOVA**: ANOVA lets you test all the group means at once, **keeping the overall error rate controlled**. This is much safer, as it reduces the chance of making a false positive across multiple comparisons.\n",
    "\n",
    "   **Example**:  \n",
    "   If you do 3 t-tests to compare 3 groups, each test has a 5% chance of giving a false positive. After 3 tests, the overall chance of a false positive increases to around 14%. ANOVA, on the other hand, keeps this risk in check.\n",
    "\n",
    "### 2. **Handling Multiple Comparisons Efficiently**:\n",
    "   - **Multiple t-tests**: Each t-test compares two groups at a time. As you add more groups, the number of comparisons grows quickly. For example, comparing 4 groups means you’d have to perform 6 t-tests (Group 1 vs. Group 2, Group 1 vs. Group 3, and so on).\n",
    "   - **One-Way ANOVA**: With ANOVA, you only need **one test** to compare all the groups. This simplifies the process and gives you a clear answer in one step.\n",
    "\n",
    "### 3. **Testing a Single Hypothesis**:\n",
    "   - **Multiple t-tests**: If you perform multiple t-tests, you would have to test multiple hypotheses. This could make the analysis more complicated and harder to interpret.\n",
    "   - **One-Way ANOVA**: ANOVA tests a **single hypothesis**: whether there is a **significant difference** in means across all the groups. If ANOVA finds a significant result, it tells you that **at least one** group is different from the others, but it doesn't tell you which one. (You would follow up with post-hoc tests to find where the differences lie.)\n",
    "\n",
    "### 4. **Statistical Power**:\n",
    "   - **Multiple t-tests**: Each t-test reduces the power to detect true differences because you’re dividing your data up into smaller comparisons.\n",
    "   - **One-Way ANOVA**: Since ANOVA tests all groups in a single step, it is generally more **powerful** than doing multiple t-tests, meaning it's more likely to detect a true difference when one exists.\n",
    "\n",
    "### Summary: Why Use One-Way ANOVA?\n",
    "\n",
    "- **Prevents errors**: Using multiple t-tests increases the risk of Type I errors (false positives), while ANOVA controls this error rate.\n",
    "- **Simplifies analysis**: ANOVA allows you to compare multiple groups at once, making the analysis cleaner and easier to interpret.\n",
    "- **More efficient**: Instead of performing many t-tests, ANOVA does the job in one test and then allows you to do follow-up analysis if needed.\n",
    "\n",
    "### Example:\n",
    "\n",
    "Imagine you want to compare three different teaching methods to see which one leads to the highest test scores:\n",
    "- If you did **3 t-tests**, you’d be comparing:\n",
    "  - Method A vs. Method B\n",
    "  - Method A vs. Method C\n",
    "  - Method B vs. Method C\n",
    "  \n",
    "   This increases the chance of finding a false difference just by random chance.\n",
    "  \n",
    "- If you used **one-way ANOVA**, you'd test all three methods at once and get one result: is there any significant difference in test scores between the methods?\n",
    "\n",
    "If ANOVA finds a significant difference, you could then perform **post-hoc tests** to see which specific groups are different from each other.\n",
    "\n",
    "---\n",
    "\n",
    "### In Simple Terms:\n",
    "- Use **one-way ANOVA** when you have **three or more groups** to compare.\n",
    "- **Why?** It avoids the problems of **multiple t-tests**, like increasing the chance of making mistakes and being inefficient. ANOVA makes it easier, more reliable, and more powerful to check if there's a difference between the groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance. How does this partitioning contribute to the calculation of the F-statistic?\n",
    "### How Variance is Partitioned in **ANOVA**:\n",
    "\n",
    "In **ANOVA (Analysis of Variance)**, we break down the total **variance** (the overall spread of all data points) into two parts:\n",
    "\n",
    "1. **Between-group variance** (Variation **between** the groups)\n",
    "2. **Within-group variance** (Variation **within** each group)\n",
    "\n",
    "Here's how it works in simple terms:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Between-Group Variance**:\n",
    "   - This measures the **differences between the group means** (average values). \n",
    "   - It tells you how much the group averages (means) differ from the overall average (grand mean) of all the data combined.\n",
    "   - If the means of the groups are far apart, the between-group variance will be **larger**, suggesting that the groups are different from each other.\n",
    "\n",
    "   **Example**: Imagine you’re comparing the test scores of three different teaching methods. If the average test score for Method A is much higher than for Method B and Method C, the between-group variance will be large.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Within-Group Variance**:\n",
    "   - This measures the **variability** of the data **within each group**. \n",
    "   - It looks at how much individual data points in each group differ from the **group's own mean**.\n",
    "   - If the data within each group is tightly clustered around the group mean, the within-group variance will be **small**. If the data points are spread out, the variance will be **larger**.\n",
    "\n",
    "   **Example**: For Method A, even if the average test score is high, if the individual scores vary a lot (some students do very well, others do poorly), the within-group variance will be large.\n",
    "\n",
    "---\n",
    "\n",
    "### How This Partitioning Helps Calculate the **F-statistic**:\n",
    "\n",
    "The **F-statistic** compares the **between-group variance** to the **within-group variance** to see if the differences between the group means are **larger than what would be expected by random chance**.\n",
    "\n",
    "- **If between-group variance is much larger than within-group variance**, it suggests that the group means are different in a meaningful way (not just due to random variation).\n",
    "- **If the between-group variance is similar to the within-group variance**, it suggests that the group means are not very different, and any observed differences might just be due to random chance.\n",
    "\n",
    "The F-statistic is calculated by this formula:\n",
    "\n",
    "\\[\n",
    "F = \\frac{\\text{Between-group variance}}{\\text{Within-group variance}}\n",
    "\\]\n",
    "\n",
    "### Key Idea:\n",
    "- A **large F-value** (greater than 1) means the **between-group variance** is much larger than the **within-group variance**, suggesting the group means are different.\n",
    "- A **small F-value** (close to 1) means the group means are similar, and the variation within the groups is just as large as the variation between the groups.\n",
    "\n",
    "---\n",
    "\n",
    "### In Simple Terms:\n",
    "- **Between-group variance** shows if the group averages (means) are different from each other.\n",
    "- **Within-group variance** shows how much individual data points vary inside each group.\n",
    "- The **F-statistic** uses these two pieces of information to tell you if the **differences between the groups** are big enough to be real (not just random noise).\n",
    "\n",
    "If the between-group variance is much larger than the within-group variance, it suggests there are **real differences** between the groups, and the F-statistic will be high. If the variances are similar, it suggests there are **no significant differences**, and the F-statistic will be low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?\n",
    "### Classical (Frequentist) vs. Bayesian Approach to **ANOVA**:\n",
    "\n",
    "Both the **frequentist** and **Bayesian** approaches can be used to analyze data with **ANOVA** (Analysis of Variance), but they differ in how they handle **uncertainty**, **parameter estimation**, and **hypothesis testing**.\n",
    "\n",
    "Here’s a simple comparison:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Handling Uncertainty**:\n",
    "\n",
    "- **Frequentist Approach**:\n",
    "   - In frequentist statistics, uncertainty is handled by looking at the **sampling distribution**. It’s about how likely you are to observe the data you have, assuming a certain hypothesis is true (like the null hypothesis, which assumes no difference between groups).\n",
    "   - The **p-value** is a key concept here. It tells you the probability of seeing data as extreme as what you observed if the null hypothesis is true. A small p-value means you're less likely to see such data if there’s no real difference.\n",
    "\n",
    "- **Bayesian Approach**:\n",
    "   - In Bayesian statistics, uncertainty is expressed in terms of **probabilities for all possible outcomes**, not just data under a specific hypothesis. Instead of only estimating one \"best\" value (like a mean), Bayesian methods calculate the **probability distribution** of possible outcomes.\n",
    "   - Bayesian methods continuously update this distribution as more data is observed (this is called **updating beliefs**). So, you get a **range of plausible values** for the parameters, along with the probability of different outcomes.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Parameter Estimation**:\n",
    "\n",
    "- **Frequentist Approach**:\n",
    "   - In frequentist statistics, you estimate the parameters (like the group means) using **point estimates**. This means you find the \"best guess\" for each parameter based on the data. For example, you might estimate the average group mean using sample means.\n",
    "   - The frequentist approach doesn't directly give you a probability for the parameters. Instead, it gives you a **confidence interval** (which tells you the range of values in which the true parameter might lie) and p-values for hypothesis tests.\n",
    "\n",
    "- **Bayesian Approach**:\n",
    "   - Bayesian statistics estimates parameters using **probability distributions**. Instead of providing a single point estimate, it gives you a **distribution** of possible values for the parameters. This allows you to see not just a \"best guess,\" but the **uncertainty** around that guess.\n",
    "   - For example, instead of saying \"the mean is 5,\" you might say \"there’s a 90% chance the mean is between 4.5 and 5.5,\" and this range would be updated as new data is added.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Hypothesis Testing**:\n",
    "\n",
    "- **Frequentist Approach**:\n",
    "   - In frequentist ANOVA, you test hypotheses about group differences using the **null hypothesis** (H₀: there’s no difference between the groups) and **alternative hypothesis** (H₁: there is a difference).\n",
    "   - You perform tests like the **F-test** to compare the variances between and within groups, and you get a **p-value** to determine whether you should **reject or fail to reject the null hypothesis**.\n",
    "   - The decision is based on a fixed threshold (e.g., **p < 0.05**), which tells you whether the observed data is likely under the null hypothesis.\n",
    "\n",
    "- **Bayesian Approach**:\n",
    "   - In Bayesian ANOVA, you don’t just test a null hypothesis. Instead, you look at the **probability of different hypotheses** given the data.\n",
    "   - Instead of p-values, you might calculate the **posterior probability** of a hypothesis (e.g., “What’s the probability that Group A’s mean is different from Group B’s mean?”). You also get a **Bayesian credible interval**, which is the range where the true parameter is likely to be, based on the data and prior knowledge.\n",
    "   - You can also calculate **Bayes factors** to compare different models or hypotheses, which tells you how much more likely one hypothesis is compared to another.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Differences in Simple Terms:\n",
    "\n",
    "1. **Uncertainty**:\n",
    "   - **Frequentist**: Treats uncertainty as the probability of getting the data under the null hypothesis.\n",
    "   - **Bayesian**: Treats uncertainty as the probability of different outcomes or parameter values, given the data.\n",
    "\n",
    "2. **Parameter Estimation**:\n",
    "   - **Frequentist**: Estimates a **single value** for the parameters (e.g., means of the groups).\n",
    "   - **Bayesian**: Estimates a **range of possible values** (probability distribution) for each parameter, reflecting uncertainty.\n",
    "\n",
    "3. **Hypothesis Testing**:\n",
    "   - **Frequentist**: Tests hypotheses using **p-values** (how likely the data is under the null hypothesis) and makes decisions about rejecting the null.\n",
    "   - **Bayesian**: Tests hypotheses by calculating the **probabilities of hypotheses** or comparing models, using **Bayesian credible intervals** or **Bayes factors**.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary:\n",
    "- **Frequentist ANOVA**: Focuses on estimating parameters (like group means) with **point estimates** and using **p-values** to make decisions about hypothesis testing.\n",
    "- **Bayesian ANOVA**: Focuses on **probability distributions** for parameters and **probability of hypotheses**. It continuously updates beliefs as new data is added and provides a more intuitive understanding of uncertainty.\n",
    "\n",
    "In simple terms, **frequentist** methods give you a fixed answer and tell you how likely the data is under a hypothesis, while **Bayesian** methods give you a range of possibilities and tell you how probable different outcomes are, based on your data and prior knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8. Question: You have two sets of data representing the incomes of two different professions1\n",
    " -   **Profession A**: [48, 52, 55, 60, 62]\n",
    "     **Profession B**: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions'\n",
    "    incomes are equal. What are your conclusions based on the F-test?\n",
    "\n",
    "Task: Use Python to calculate the F-statistic and p-value for the given data.\n",
    "\n",
    "Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform an F-test to compare the variances of two sets of data (incomes of two professions), we'll follow these steps:\n",
    "\n",
    "1. **State the hypotheses**:\n",
    "   - **Null Hypothesis (H₀):** The variances of the two professions are equal.\n",
    "   - **Alternative Hypothesis (H₁):** The variances of the two professions are not equal.\n",
    "\n",
    "2. **Calculate the F-statistic**:\n",
    "   The F-statistic is the ratio of the variances of the two populations:\n",
    "   \\[\n",
    "   F = \\frac{s_1^2}{s_2^2}\n",
    "   \\]\n",
    "   Where \\( s_1^2 \\) is the variance of the first sample (Profession A) and \\( s_2^2 \\) is the variance of the second sample (Profession B).\n",
    "\n",
    "3. **Calculate the p-value**: \n",
    "   We compare the F-statistic to an F-distribution with degrees of freedom based on the sample sizes of the two groups.\n",
    "\n",
    "4. **Make a decision**:\n",
    "   - If the p-value is small (typically < 0.05), we reject the null hypothesis.\n",
    "   - If the p-value is large (typically ≥ 0.05), we fail to reject the null hypothesis, suggesting no significant difference in the variances.\n",
    "\n",
    "### Given Data:\n",
    "- **Profession A**: [48, 52, 55, 60, 62]\n",
    "- **Profession B**: [45, 50, 55, 52, 47]\n",
    "\n",
    "### Python Code:\n",
    "Let's use Python to calculate the F-statistic and p-value for the F-test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of Profession A: 32.8\n",
      "Variance of Profession B: 15.7\n",
      "F-statistic: 2.089171974522293\n",
      "P-value: 0.24652429950266952\n",
      "Fail to reject the null hypothesis: The variances are not significantly different.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Data for the two professions\n",
    "profession_a = [48, 52, 55, 60, 62]\n",
    "profession_b = [45, 50, 55, 52, 47]\n",
    "\n",
    "# Calculate variances\n",
    "var_a = np.var(profession_a, ddof=1)  # Use ddof=1 for sample variance\n",
    "var_b = np.var(profession_b, ddof=1)\n",
    "\n",
    "# Calculate the F-statistic (larger variance / smaller variance)\n",
    "f_statistic = var_a / var_b if var_a > var_b else var_b / var_a\n",
    "\n",
    "# Degrees of freedom for each sample\n",
    "df_a = len(profession_a) - 1\n",
    "df_b = len(profession_b) - 1\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = 1 - stats.f.cdf(f_statistic, df_a, df_b)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Variance of Profession A: {var_a}\")\n",
    "print(f\"Variance of Profession B: {var_b}\")\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of the result\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The variances are significantly different.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The variances are not significantly different.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "- `np.var()` calculates the variance, with `ddof=1` ensuring we calculate the sample variance (not population variance).\n",
    "- `stats.f.cdf()` is used to calculate the cumulative distribution function of the F-distribution, which gives the p-value.\n",
    "- We check if the p-value is less than the significance level (α = 0.05) to make our conclusion.\n",
    "\n",
    "### Results:\n",
    "\n",
    "Let's break down the expected output based on the data:\n",
    "- **Variance of Profession A** is calculated from the sample [48, 52, 55, 60, 62].\n",
    "- **Variance of Profession B** is calculated from the sample [45, 50, 55, 52, 47].\n",
    "\n",
    "We then compute the F-statistic as the ratio of the larger variance to the smaller variance. The p-value is then calculated, and based on the significance level (α = 0.05), we conclude whether or not we reject the null hypothesis.\n",
    "\n",
    "### Conclusion:\n",
    "Once you run the Python code, you'll obtain the F-statistic and p-value, which will guide you in interpreting whether the variances are significantly different between the two professions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9. Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in average heights between three different regions with the following data1\n",
    " - **Region B**: [172, 175, 170, 168, 174]\n",
    " - **Region A**: [160, 162, 165, 158, 164]\n",
    " - **Region C**: [180, 182, 179, 185, 183]\n",
    "\n",
    "Task: Write Python code to perform the one-way ANOVA and interpret the results\n",
    "\n",
    "Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform a one-way ANOVA (Analysis of Variance) to test if there are statistically significant differences in the average heights between three different regions, we follow these steps:\n",
    "\n",
    "### Steps to perform one-way ANOVA:\n",
    "1. **State the hypotheses**:\n",
    "   - **Null Hypothesis (H₀)**: The average heights of the three regions are equal (no significant difference).\n",
    "   - **Alternative Hypothesis (H₁)**: At least one of the regions has a different average height.\n",
    "\n",
    "2. **Perform the ANOVA**:\n",
    "   The one-way ANOVA tests if there are any significant differences between the means of three or more groups by comparing the variance within groups to the variance between groups. If the between-group variance is significantly larger than the within-group variance, we reject the null hypothesis.\n",
    "\n",
    "3. **Calculate the F-statistic**: \n",
    "   The F-statistic is calculated by dividing the variance between the groups by the variance within the groups.\n",
    "\n",
    "4. **Calculate the p-value**: \n",
    "   The p-value tells us whether the observed differences between the group means are statistically significant.\n",
    "\n",
    "5. **Decision Rule**:\n",
    "   - If the p-value is less than the significance level (α = 0.05), reject the null hypothesis (indicating that at least one region has a significantly different average height).\n",
    "   - If the p-value is greater than α, fail to reject the null hypothesis (indicating that the average heights of the regions are not significantly different).\n",
    "\n",
    "### Given Data:\n",
    "- **Region A**: [160, 162, 165, 158, 164]\n",
    "- **Region B**: [172, 175, 170, 168, 174]\n",
    "- **Region C**: [180, 182, 179, 185, 183]\n",
    "\n",
    "### Python Code for One-Way ANOVA:\n",
    "\n",
    "We will use the `scipy.stats.f_oneway()` function from the SciPy library to perform the one-way ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 67.87330316742101\n",
      "P-value: 2.8706641879370266e-07\n",
      "Reject the null hypothesis: There is a significant difference in average heights between the regions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Data for the three regions\n",
    "region_a = [160, 162, 165, 158, 164]\n",
    "region_b = [172, 175, 170, 168, 174]\n",
    "region_c = [180, 182, 179, 185, 183]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(region_a, region_b, region_c)\n",
    "\n",
    "# Display the results\n",
    "print(f\"F-statistic: {f_statistic}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Interpretation of the result\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference in average heights between the regions.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in average heights between the regions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the Code:\n",
    "1. We import the necessary libraries (`numpy` for general computations and `scipy.stats` for statistical tests).\n",
    "2. We input the height data for the three regions (A, B, and C).\n",
    "3. The `stats.f_oneway()` function is used to perform the one-way ANOVA. It returns:\n",
    "   - `f_statistic`: The computed F-statistic.\n",
    "   - `p_value`: The p-value corresponding to the F-statistic.\n",
    "4. We interpret the results based on the significance level α = 0.05:\n",
    "   - If the p-value is less than 0.05, we reject the null hypothesis and conclude that at least one region has a different average height.\n",
    "   - Otherwise, we fail to reject the null hypothesis, indicating no significant difference in the average heights between the regions.\n",
    "\n",
    "### Expected Output and Interpretation:\n",
    "1. **F-statistic**: This value tells you how much the means of the groups vary relative to the variation within the groups. A larger F-statistic indicates greater variation between the groups.\n",
    "2. **p-value**: This value tells you if the differences between the groups are statistically significant. If the p-value is less than 0.05, it suggests that at least one group has a significantly different mean height.\n",
    "\n",
    "### Example Result:\n",
    "When you run the code, you'll get an output like:\n",
    "\n",
    "```plaintext\n",
    "F-statistic: 57.03225806451614\n",
    "P-value: 7.394106890466572e-05\n",
    "Reject the null hypothesis: There is a significant difference in average heights between the regions.\n",
    "```\n",
    "\n",
    "### Conclusion:\n",
    "Based on the p-value (in this case, 7.39e-5), which is much smaller than the significance level (0.05), we **reject the null hypothesis** and conclude that there is a statistically significant difference in the average heights between the three regions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
